#include<iostream>
#include<stdexcept>
#include<OpenNI.h>
#include<opencv2/opencv.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>

int a;

using namespace cv;
using namespace std;

class DepthSensor
{
private:

	void changeResolution(openni::VideoStream& stream)
		{
			openni::VideoMode mode = stream.getVideoMode();
			mode.setFps(30);
			stream.setVideoMode(mode);
		}



public:
	void initialize(){
		
			//デバイスを習得する
			openni::Status ret = device.open( openni::ANY_DEVICE );
			if ( ret != openni::STATUS_OK){
				throw std::runtime_error( "openni::Device::open() failed.");
			}

			//カラーストリームを有効にする
			colorStream.create(device, openni::SENSOR_COLOR);
			//changeResolution(colorStream);
			colorStream.start();

			//Depthストリームを有効にする
			depthStream.create(device, openni::SENSOR_DEPTH);
			depthStream.start();
				
	}
	//フレームの更新処理
	void update()
		{
			openni::VideoFrameRef colorFrame;
			openni::VideoFrameRef depthFrame;

			//更新されたフレームを習得する
			colorStream.readFrame( &colorFrame );
			depthStream.readFrame( &depthFrame );

			//フレームのデータを表示できる形に変換する
			colorImage = showColorStream( colorFrame );
			depthImage = showDepthStream( depthFrame );

			//フレームのデータを表示する
			imshow("Color Stream", colorImage);
			imshow("Depth Stream", depthImage);

			showCenterDistance(depthImage, depthFrame);
		}
	//カラーストリームを幼児できる形にする
	Mat showColorStream(const openni::VideoFrameRef& colorFrame)
		{
			//OpenCVのかタイに変換する
			Mat colorImage = Mat(colorFrame.getHeight(),
										 colorFrame.getWidth(),
										 CV_8UC3, (unsigned char*)colorFrame.getData());

			//BGRの並びをRGBに変換する
			cvtColor(colorImage, colorImage, CV_RGB2BGR);

			return colorImage;
		}

	Mat showDepthStream(const openni::VideoFrameRef& depthFrame){
			//距離データを画像化する(16bit)
			Mat depthImage = Mat(depthFrame.getHeight(),
								 depthFrame.getWidth(),
								 CV_16UC1, (unsigned short*)depthFrame.getData());

			//0 〜 10000ミリメートルまでのデータを0〜255(8bit)にする
			depthImage.convertTo(depthImage, CV_8U, 255.0 / 10000);

			//中心点の距離を表示する
			showCenterDistance(depthImage, depthFrame);

			return depthImage;
	}

	void showCenterDistance(Mat& depthImage, const openni::VideoFrameRef& depthFrame){

		openni::VideoMode videoMode = depthStream.getVideoMode();

		int centerX = videoMode.getResolutionX() / 2;
		int centerY = videoMode.getResolutionY() / 2;
		int centerIndex = (centerY * videoMode.getResolutionX()) + centerX;

		unsigned short* depth = (unsigned short*)depthFrame.getData();

		stringstream ss;
		ss << "Center Point: " << depth[centerIndex];
		cv::putText(depthImage, ss.str(), cv::Point(0, 50),
					cv::FONT_HERSHEY_SIMPLEX, 1.0, cv::Scalar(255));
	}
	


private:

	openni::Device device;
	openni::VideoStream colorStream;
	
	openni::VideoStream depthStream;

	
	Mat colorImage;
	Mat depthImage;


};

int main(int arg, const char * argv[])
{
	try{
		//OpenNIを初期化する
		openni::OpenNI::initialize();

		//センサーを初期化する
		DepthSensor sensor;
		sensor.initialize();

		//メインループ
		while(1){
			sensor.update();
			int key = waitKey(10);
			if(key=='q'){
			}}}
	catch(std::exception&){
		std::cout << openni::OpenNI::getExtendedError() << std::endl;
	}
	return 0;
}
	
			   
nn
